<!doctype linuxdoc system>
<article>
<title>Squid v1.2 Programmers Guide</title>
<author>Duane Wessels, Squid Developers

<abstract>
Squid is a WWW Cache application developed by the National Laboratory
for Applied Network Research and members of the Web Caching community.
Squid is implemented as a single, non-blocking process based around
a BSD select() loop.  This document describes the operation of the Squid
source code and is intended to be used by others who wish to customize
or improve it.
</abstract>

<toc>


<!-- %%%% Chapter : INTRODUCTION %%%% -->
<sect>Introduction

<P>
The Squid source code has evolved more from empirical observation and
tinkering, rather than a solid design process.  It carries a legacy of
being ``touched'' by numerous individuals, each with somewhat different
techniques and terminology.  

<P>
Squid is a single-process proxy server.  Every request is handled by
the main process, with the exception of FTP.  However, Squid does not
use a ``threads package'' such has Pthreads.  While this might be 
easier to code, it suffers from portability and performance problems.
Instead Squid maintains data structures and state information for
each active request.

<P>
The code is often difficult to follow because there are no explicit
state variables for the active requests.  Instead, thread execution
progresses as a sequence of ``callback functions'' which get executed
when I/O is ready to occur, or some other event has happened.  As
a callback function completes, it is responsible for registering the
next callback function for subsequent I/O.

<P>
Note there is only a pseudo-consistent naming scheme.  In most 
cases functions are named like <tt/moduleFooBar()/.  However, there
are also some functions named like <tt/module_foo_bar()/.

<P>
Note that the Squid source changes rapidly, and some parts of this
document may become out-of-date.  If you find any inconsistencies, please
feel free to notify
<url url="mailto:squid-dev@nlanr.net"
name="the Squid Developers">.

<sect1>Conventions

<P>
Function names and file names will be written in a courier font, such
as <tt/store.c/ and <tt/storeRegister()/.  Data structures and their
members will be written in an italicised font, such as <em/StoreEntry/.

<sect1>The Big Picture

<P>
Squid consists of the following major components

<sect2>Client Side

<P>
<em/Files:/ <tt/client_side.c/

<P>
    Here new client connections are accepted, parsed, and processed.
    This is where we determine if the request is a cache HIT,
    REFRESH, MISS, etc.  With HTTP/1.1 we may have multiple requests
    from a single TCP connection.  Per-connection state information
    is held in a data structure called <em/ConnStateData/.  Per-request
    state information is stored in the <em/clientHttpRequest/ structure.
    
<sect2>Server Side

<P>
<em/Files:/
    <tt/proto.c/,
    <tt/http.c/,
    <tt/ftp.c/,
    <tt/gopher.c/,
    <tt/wais.c/,
    <tt/ssl.c/,
    <tt/pass.c/

<P>
    These routines are responsible for forwarding cache misses
    to other servers, depending on the protocol.  Cache misses
    may be forwarded to either origin servers, or other proxy caches.
    Note that all requests (FTP, Gopher) to other
    proxies are sent as HTTP requests.  
    <tt/gopher.c/ is somewhat complex and gross because it must
    convert from the Gopher protocol to HTTP.  Wais and Gopher don't
    receive much attention because they comprise a relatively insignificant
    portion of Internet traffic.

<P>
    <tt/ssl.c/ handles SSL requests (the CONNECT method) and
    <tt/pass.c/ (``passthrough'') handles uncachable requests which
    the cache doesn't really care about.   These two modules basically
    pass bits back and forth between client and server.  Note they do
    not use a <em/StoreEntry/ to do so.  About the only difference
    between the two is that the SSL module sends a special ``connection
    established'' message.

<sect2>Storage Manager

<P>
<em/Files:/
    <tt/store_clean.c/,
    <tt/store_client.c/,
    <tt/store_dir.c/,
    <tt/store_key_md5.c/,
    <tt/store_log.c/,
    <tt/store_rebuild.c/,
    <tt/store_swapin.c/,
    <tt/store_swapmeta.c/,
    <tt/store_swapout.c/,
    <tt/store.c/

<P>
    The Storage Manager is the glue between client and server sides.
    Every object saved in the cache is allocated a <em/StoreEntry/
    structure.  While the object is being accessed, it also has a 
    <em/MemObject/ structure.

<P>
    Squid can quickly locate cached objects because it keeps (in memory) a hash
    table of all <em/StoreEntry/'s.  The keys for the hash
    table are MD5 checksums of the objects URI.  In addition there is
    also a doubly-linked list of <em/StoreEntry/'s used for the LRU
    replacement algorithm.  When an entry is accessed, it is moved to
    the head of the LRU list.  When Squid needs to replace cached objects,
    it takes objects from the tail of the LRU list.

<P>
    Objects are saved to disk in a two-level directory structure.  For
    each object the <em/StoreEntry/ includes a 4-byte <em/fileno/
    field.  This file number is converted to a disk pathname by a
    simple algorithm which evenly distributes the files across all 
    cache directories.  A cache swap file consists of two parts:
    the cache metadata, and the object data.  Note the object 
    data includes the full HTTP reply---headers and body.  The HTTP
    reply headers are not the same as the cache metadata.

<P>
    Client-side reqeusts register themselves with a <em/StoreEntry/
    to be notified when new data arrives.  Multiple clients may
    receive data via a single <em/StoreEntry/.  For POST and
    PUT request, this process works in reverse.  Server-side functions
    are notified when additional data is read from the client.

<sect2>Peer Selection

<P>
<em/Files:/
	<tt/peer_select.c/

<P>
    These functions are responsible for selecting
    one (or none) of the neighbor caches as the appropriate forwarding
    location.

<sect2>Access Control

<P>
<em/Files:/
	<tt/acl.c/

<P>
    These functions are responsible for allowing
    or denying a request, based on a number of different parameters.
    These parameters include the client's IP address, the hostname
    of the requested resource, the request method, etc.
    Some of the necessary information may not be immedaitely available,
    for example the origin server's IP address.  In these cases, 
    the ACL routines initiate lookups for the necessary information and
    continues the access control checks when the information is
    available.

<sect2>Network Communication

<P>
<em/Files:/
	<tt/comm.c/

<P>
    These are the routines for communicating over
    TCP and UDP network sockets.  Here is where sockets are opened,
    closed, read, and written.  In addition, note that the heart of
    Squid (<tt/comm_select()/ or <tt/comm_poll()/) exists here, even
    though it handles all file descriptors, not just network sockets.
    These routines do not support queueing multiple
    blocks of data for writing.  Consequently, a callback occurs
    for every write request.

<sect2>File/Disk I/O

<P>
<em/Files:/
	<tt/disk.c/

<P>
    Routines for reading and writing disk files (and FIFOs).
    Reasons for separating network and
    disk I/O functions are partly historical, and partly because of
    different behaviours.  For example, we don't worry about getting a
    ``No space left on device'' error for network sockets.  The disk
    I/O routines support queueing of multiple blocks for writing.
    In some cases, it is possible to merge multiple blocks into
    a single write request.  The write callback does not necessarily
    occur for every write request.

<sect2>Neighbors

<P>
<em/Files:/
	<tt/neighbors.c/

<P>
    Maintains the list of neighbor caches.  Sends and receives 
    ICP messages to neighbors.  Decides which neighbors to
    query for a given request.  File: <tt/neighbors.c/.

<sect2>IP/FQDN Cache

<P>
<em/Files:/
	<tt/ipcache.c/, <tt/fqdncache.c/

<P>
    A cache of name-to-address and address-to-name lookups.  These are
    hash tables keyed on the names and addresses.
    <tt/ipcache_nbgethostbyname()/ and <tt/fqdncache_nbgethostbyaddr()/
    implement the non-blocking lookups.  Files: <tt/ipcache.c/,
    <tt/fqdncache.c/.

<sect2>Cache Manager

<P>
<em/Files:/
	<tt/objcache.c/, <tt/stat.c/

<P>
	This provides access to certain information needed by the
	cache administrator.  A companion program, <em/cachemgr.cgi/
	can be used to make this information available via a Web
	broswer.  Cache manager requests to Squid are made with a 
	special URL of the form
<verb>
	cache_object://hostname/operation
</verb>
	The cache manager provides essentially ``read-only'' access
	to information.  It does not provide a method for configuring
	Squid while it is running.

<sect2>Network Measurement Database

<P>
<em/Files:/
	<tt/net_db.c/

<P>
	In a number of situation, Squid finds it useful to know the
	estimated network round-trip time (RTT) between itself and
	origin servers.  A particularly useful is example is
	the peer selection algorithm.  By making RTT measurements, a
	Squid cache will know if it, or one if its neighbors, is closest
	to a given origin server.  The actual measurements are made
	with the <em/pinger/ program, described below.  The measured
	values are stored in a database indexed under two keys.  The 
	primary index field is the /24 prefix of the origin server's
	IP address.  Secondly, a hash table of fully-qualified host
	names have have data structures with links to the appropriate
	network entry.  This allows Squid to quickly look up measurements
	when given either an IP address, or a host name.  The /24 prefix
	aggregation is used to reduce the overall database size.  File:
	<tt/net_db.c/.

<sect2>Redirectors

<P>
<em/Files:/
	<tt/redirect.c/

<P>
	Squid has the ability to rewrite requests from clients.  After
	checking the access controls, but before checking for cache hits,
	requested URLs may optionally be written to an external
	<em/redirector/ process.  This program, which can be highly
	customized, may return a new URL to replace the original request.
	Common applications for this feature are extended access controls
	and local mirroring.  File: <tt/redirect.c/.

<sect2>Autonomous System Numbers

<P>
<em/Files:/
	<tt/asn.c/

<P>
	Squid supports Autonomous System (AS) numbers as another 
	access control element.  The routines in <tt/asn.c/
	query databases which map AS numbers into lists of CIDR
	prefixes.  These results are stored in a radix tree which
	allows fast searching of the AS number for a given IP address.
	
<sect2>Asynchronous I/O Operations

<P>
<em/Files:/
	<tt/async_io.c/, <tt/aiops.c/

<P>
	These routines in <tt/async_io.c/ and <tt/aiops.c/ 
	implement blocking disk operations in a set of thread (child)
	processes.

<sect2>Configuation File Parsing

<P>
<em/Files:/
	<tt/cf.data.pre/,
	<tt/cf_gen.c/,
	<tt/cf_parser.c/,
	<tt/cache_cf.c/

<P>
	The primary configuration file specification is in the file
	<tt/cf.data.pre/.  A simple utility program, <tt/cf_gen/,
	reads the <tt/cf.data.pre/ file and generates <tt/cf_parser.c/
	and <tt/squid.conf/.  <tt/cf_parser.c/ is included directly
	into <tt/cache_cf.c/ at compile time.

<sect2>Callback Data Database

<P>
<em/Files:/
	<tt/cbdata.c/

<P>
	Squid's extensive use of callback functions makes it very
	susceptible to memory access errors.  Care must be taken
	so that the <tt/callback_data/ memory is still valid when
	the callback function is executed.  The routines in <tt/cbdata.c/
	provide a uniform method for managing callback data memory,
	cancelling callbacks, and preventing erroneous memory accesses.

<sect2>Debugging

<P>
<em/Files:/
	<tt/debug.c/

<P>
	Squid includes extensive debugging statements to assist in
	tracking down bugs and strange behaviour.  Every debug statement
	is assigned a section and level.  Usually, every debug statement
	in the same source file has the same section.  Levels are chosen
	depending on how much output will be generated, or how useful the
	provided information will be.  The <em/debug_options/ line 
	in the configuration file determines which debug statements will
	be shown and which will not.  The <em/debug_options/ line
	assigns a maximum level for every section.  If a given debug
	statement has a level less than or equal to the configured
	level for that section, it will be shown.  This description
	probably sounds more complicated than it really is.
	File: <em/debug.c/.  Note that <tt/debug()/ itself is a macro.

<sect2>Error Generation

<P>
<em/Files:/
	<tt/errorpage.c/

<P>
	The routines in <tt/errorpage.c/ generate error messages from
	a template file and specific request parameters.  This allows
	for customized error messages and multilingual support.

<sect2>Event Queue

<P>
<em/Files:/
	<tt/event.c/

<P>
	The routines in <tt/event.c/ maintain a linked-list event
	queue for functions to be executed at a future time.  The
	event queue is used for periodic functions such as performing
	cache replacement, cleaning swap directories, as well as one-time
	functions such as ICP query timeouts.
	
<sect2>Filedescriptor Managment
<P>
<em/Files:/
	<tt/fd.c/

<P>
	Here we track the number of filedescriptors in use, and the
	number of bytes which has been read from or written to each
	file descriptor.


<sect2>Hashtable Support
<P>
<em/Files:/
	<tt/hash.c/

<P>
	These routines implement generic hash tables.  A hash table
	is created with a function for hashing the key values, and a
	function for comparing the key values.

<sect2>HTTP Anonymization
<P>
<em/Files:/
	<tt/http-anon.c/

<P>
	These routines support anonymizing of HTTP requests leaving
	the cache.  Either specific request headers will be removed
	(the ``standard'' mode), or only specific request headers
	will be allowed (the ``paranoid'' mode).

<sect2>Internet Cache Protocol
<P>
<em/Files:/
	<tt/icp_v2.c/,
	<tt/icp_v3.c/

<P>
	Here we implement the Internet Cache Protocol.  This 
	protocol is documented in the RFC 2186 and RFC 2187.
	The bulk of code is in the <tt/icp_v2.c/ file.  The 
	other, <tt/icp_v3.c/ is a single function for handling
	ICP queries from Netcache/Netapp caches; they use
	a different version number and a slightly different message
	format.

<sect2>Ident Lookups
<P>
<em/Files:/
	<tt/ident.c/

<P>
	These routines support RFC 931 ``Ident'' lookups.   An ident
	server running on a host will report the user name associated
	with a connected TCP socket.  Some sites use this facility for
	access control and logging purposes.

<sect2>Memory Management
<P>
<em/Files:/
	<tt/mem.c/

<P>
	These routines allocate and manage pools of memory for
	frequently-used data structures.  When the <em/memory_pools/
	configuration option is enabled, unused memory is not actually
	freed.  Instead it is kept for future use.  This may result
	in more efficient use of memory at the expense of a larger
	process size.

<sect2>Multicast Support
<P>
<em/Files:/
	<tt/multicast.c/

<P>
	Currently, multicast is only used for ICP queries.   The
	routines in this file implement joining a UDP 
	socket to a multicast group (or groups), and setting
	the multicast TTL value on outgoing packets.

<sect2>Persistent Server Connections
<P>
<em/Files:/
	<tt/pconn.c/

<P>
	These routines manage idle, persistent HTTP connections
	to origin servers and neighbor caches.  Idle sockets
	are indexed in a hash table by their socket address
	(IP address and port number).  Up to 10 idle sockets
	will be kept for each socket address, but only for
	15 seconds.  After 15 seconds, idle socket connections
	are closed.

<sect2>Refresh Rules

<P>
<em/Files:/
	<tt/refresh.c/

<P>
	These routines decide wether a cached object is stale or fresh,
	based on the <em/refresh_pattern/ configuration options.
	If an object is fresh, it can be returned as a cache hit.
	If it is stale, then it must be revalidated with an	
	If-Modified-Since request.

<sect2>SNMP Support
<P>
<em/Files:/
	<tt/snmp.c/,
	<tt/snmp_agent.c/,
	<tt/snmp_config.c/,
	<tt/snmp_vars.c/

<P>
	These routines implement SNMP for Squid.  At the present time,
	we have made almost all of the cachemgr information avaialble
	via SNMP.

<sect2>URN Support
<P>
<em/Files:/
	<tt/urn.c/

<P>
We are experimenting with URN support in Squid version 1.2.  Note,
we're not talking full-blown generic URN's here. This is primarily
targeted towards using URN's as an smart way of handling lists of
mirror sites.  For more details, please see
<url	url="http://squid.nlanr.net/Squid/urn-support.html"
	name="URN support in Squid">.


<sect1>External Programs

<sect2>dnsserver
<P>
<em/Files:/
	<tt/dnsserver.c/

<P>
    Because the standard <tt/gethostbyname(3)/ library call blocks,
    Squid must use external processes to actually make these calls.
    Typically there will be ten <tt/dnsserver/ processes spawned from
    Squid.  Communication occurs via TCP sockets bound to the loopback
    interface.  The functions in <tt/dns.c/ are primarily concerned
    with starting and stopping the dnsservers.  Reading and writing to
    and from the dnsservers occurs in the IP and FQDN cache modules.

<sect2>pinger
<P>
<em/Files:/
	<tt/pinger.c/

<P>
	Although it would be possible for Squid to send and recieve
	ICMP messages directly, we use an external process for
	two important reasons:
	<enum>
	<item>Because squid handles many filedescriptors simultaneously,
	we get much more accruate RTT measurements when ICMP is
	handled by a separate process.
	<item>Superuser priveleges are required to send and receive
	ICMP.  Rather than require Squid to be started as root,
	we prefer to have the smaller and simpler <em/pinger/
	program installed with setuid permissions.
	</enum>
	
<sect2>unlinkd
<P>
<em/Files:/
	<tt/unlinkd.c/

<P>
	The <tt/unlink(2)/ system call can cause a process to block
	for a significant amount of time.  Therefore we do not want
	to make unlink() calls from Squid.  Instead we pass them
	to this external process.

<sect2>redirector

<P>
<em/Files:/
	user-developed

<P>
	A redirector process reads URLs on stdin and writes (possibly
	changed) URLs on stdout.  It is implemented as an external
	process to maximize flexibility.

<sect1>Sequence of a Typical Request

<P>
<enum>
<item>
A client connetion is accepted by the <em/client-side/.  The HTTP request
is parsed.

<item>
The access controls are checked.  The client-side builds an
ACL state data structure and registers a callback function
for notification when access control checking is completed.

<item>
After the access controls have been verified, the client-side looks for
the requested object in the cache.  If is a cache hit, then the
client-side registers its interest in the <em/StoreEntry/.  Otherwise,
Squid needs to forward the request, perhaps with an If-Modified-Since
header.

<item>
The request-forwarding process begins with <tt/protoDispatch/.
This function begins the peer selection procedure, which may
involve sending ICP queries and receiving ICP replies.  The peer
selection procedure also involves checking configuration
options such as <em/never_direct/ and <em/always_direct/.

<item>
When the ICP replies (if any) have been processed, we end up
at <em/protoStart/.  This function calls an appropriate 
protocol-specific function for forwarding the request.  Here we
will assume it is an HTTP request.

<item>
The HTTP module first opens a connection to the origin server
or cache peer.  If there is no idle persistent socket available,
a new connection request is given to the Network Communication
module with a callback function.  The <tt/comm.c/ routines
may try establishing a connection multiple times before giving up.

<item>
When a TCP connection has been established, HTTP builds a request
buffer and submits it for writing on the socket.  It then registers
a read handler to receive and process the HTTP reply.

<item>
As the reply is initially received, the HTTP reply headers are
parsed and placed into a reply data structure.  As reply data
is read, it is appended to the <em/StoreEntry/.  Every time data
is appended to the <em/StoreEntry/, the client-side is 
notified of the new data via a callback function.

<item>
As the client-side is notified of new data, it copies the data
from the StoreEntry and submits it for writing on the client socket.

<item>
As data is appended to the <em/StoreEntry/, and the client(s)
read it, the data may be submitted for writing to disk.

<item>
When the HTTP module finishes reading the reply from the upstream
server, it marks the <em/StoreEntry/ as ``complete.''  The server
socket is either closed or given to the persistent connection pool
for future use.

<item>
When the client-side has written all of the object data, it unregisters
itself from the <em/StoreEntry/.  At the same time it either waits for
another request from the client, or closes the client connection.

</enum>

<!-- %%%% Chapter : MAIN LOOP %%%% -->
<sect>The Main Loop: <tt/comm_select()/

<P>
At the core of Squid is the <tt/select(2)/ system call.  Squid uses
<tt/select()/ (or alternatively <tt/poll(2)/ in recent versions) to 
process I/O on all open file descriptors.

<sect1>Comm Handlers

<P>
For every open file descriptor, there are N types of handler functions.
<itemize>
<item>Read
<item>Write
<item>Timeout
<item>Lifetime
<item>Close
</itemize>

<P>
These handlers are stored in the <em/FD_ENTRY/ structure as defined in
<tt/comm.h/.  <tt/fd_table[]/ is the global array of <em/FD_ENTRY/
structures.  The handler functions are of type <em/PF/, which is a
typedef:
<verb>
    typedef void (*PF) (int, void *);
</verb>
The close handler is really a linked list of handler functions.
Each handler also has an associated pointer <tt/(void *data)/ to
some kind of data structure.

<P>
<tt/comm_select()/ is the function which issues the select() system
call.  It scans the entire <tt/fd_table[]/ array looking for handler
functions.  Each file descriptor with a read handler will be set in
the <tt/fd_set/ read bitmask.  Similarly, write handlers are scanned and
bits set for the write bitmask.  <tt/select()/ is then called, and the
return read and write bitmasks are scanned for descriptors with pending
I/O.  For each ready descriptor, the handler is called.  Note that
the handler is cleared from the <em/FD_ENTRY/ before it is called.

<P>
After each handler is called, <tt/comm_select_incoming()/ is
called to process new HTTP and ICP requests.

<P>
Typical read handlers are
<tt/httpReadReply()/,
<tt/diskHandleRead()/,
<tt/icpHandleUdp()/,
and <tt/ipcache_dnsHandleRead()/.
Typical write handlers are
<tt/commHandleWrite()/,
<tt/diskHandleWrite()/,
and <tt/icpUdpReply()/.
The handler function is set with <tt/commSetSelect()/, with the
exception of the close handlers, which are set with
<tt/comm_add_close_handler()/.

<P>
The close handlers are normally called from <tt/comm_close()/.  
The job of the close handlers is to deallocate data structures 
associated with the file descriptor.  For this reason <tt/comm_close()/
must normally be the last function in a sequence to prevent accessing
just-freed memory.

<P>
The timeout and lifetime handlers are called for file descriptors which
have been idle for too long.  They are futher discussed in a following 
chapter.

<!-- %%%% Chapter : CLIENT REQUEST PROCESSING %%%% -->
<sect>Processing Client Requests

<!-- %%%% Chapter : STORAGE MANAGER %%%% -->
<sect>Storage Manager

<!-- %%%% Chapter : FORWARDING SELECTION %%%% -->
<sect>Forwarding Selection

<!-- %%%% Chapter : IP/FQDN CACHE %%%% -->
<sect>IP Cache and FQDN Cache

<sect1> Introduction

<P>
The IP cache is a built-in component of squid providing
Hostname to IP-Number translation functionality and managing 
the involved data-structures. Efficiency concerns require
mechanisms that allow non-blocking access to these mappings.
The IP cache usually doesn't block on a request except for special 
cases where this is desired (see below).

<sect1> Data Structures 

<P>
The data structure used for storing name-address mappings
is a small hashtable (<em>static hash_table *ip_table</em>),
where structures of type <em>ipcache_entry</em> whose most
interesting members are:

<verb>
struct _ipcache_entry {
char *name;
time_t lastref;
ipcache_addrs addrs;
struct _ip_pending *pending_head;
char *error_message;
unsigned char locks;
ipcache_status_t status:3;
}
</verb>


<sect1> External overview

<P>
Main functionality
is provided through calls to:
<descrip>
<tag>ipcache_nbgethostbyname(const char *name, IPH *handler, void *handlerdata)
</tag>
where <em/name/ is the name of the host to resolve, <em/handler/ is a 
pointer to the function to be called when the reply from the IP cache (or
the DNS if the IP cache misses) and <em/handlerdata/ is information that
is passed to the handler and does not affect the IP cache.
<tag>ipcache_gethostbyname(const char *name,int flags)</tag>
is different in that
it only checks if an entry exists in it's data-structures and does not by
default contact the DNS, unless this is requested, by setting the <em/flags/ to
<em/IP_BLOCKING_LOOKUP/ or <em/IP_LOOKUP_IF_MISS/.
<tag>ipcache_init()</tag> is called from <em/mainInitialize()/ after disk
initialization and prior to the reverse fqdn cache initialization
<tag>ipcache_restart()</tag> is called to clear the IP cache's data structures,
cancel all pending requests. Currently, it is only called from
<em/mainReconfigure/.
</descrip>

<sect1> Internal Operation 

<P>
Internally, the execution flow is as follows: On a miss, 
 <em/ipcache_getnbhostbyname/ checks whether a request for this name is already
pending, and if positive, it creates a new entry using <em/ipcacheAddNew/ with
the <em/IP_PENDING/ flag set . Then it calls <em/ipcacheAddPending/ to add a
request to the queue together with data and handler.
Else, <em/ipcache_dnsDispatch()/ is called to
directly create a DNS query or to <em/ipcacheEnqueue()/ if all no DNS port is
free.
<em/ipcache_call_pending()/ is called regularly to walk down the pending
list and call handlers. LRU clean-up is performed through <em/ipcache_purgelru()/
according to the <em/ipcache_high/ threshold.

<!-- %%%% Chapter : SERVER PROTOCOLS %%%% -->
<sect>Server Protocols
<sect1>HTTP
<sect1>FTP
<sect1>Gopher
<sect1>Wais
<sect1>SSL
<sect1>Passthrough

<!-- %%%% Chapter : TIMEOUTS %%%% -->
<sect>Timeouts

<!-- %%%% Chapter : EVENTS %%%% -->
<sect>Events

<!-- %%%% Chapter : ACCESS CONTROLS %%%% -->
<sect>Access Controls

<!-- %%%% Chapter : ICP %%%% -->
<sect>ICP

<!-- %%%% Chapter : NETDB %%%% -->
<sect>Network Measurement Database

<!-- %%%% Chapter : Error Pages %%%% -->
<sect>Error Pages

<sect>Callback Data Database

<P>
	Squid's extensive use of callback functions makes it very
	susceptible to memory access errors.  For a blocking operation
	with callback functions, the normal sequence of events is as
	follows:
<verb>
	callback_data = malloc(...);
	...
	fooOperationStart(bar, callback_func, callback_data);
	...
	fooOperationComplete(...);
	callback_func(callback_data, ....);
	...
	free(callback_data);
</verb>
	However, things become more interesting if we want or need
	to free the callback_data, or otherwise cancel the callback,
	before the operation completes.

<P>
	The callback data database lets us do this in a uniform and
	safe manner.  Every callback_data pointer must be added to the
	database.  It is then locked while the blocking operation executes
	elsewhere, and is freed when the operation completes.  The normal
	sequence of events is:
<verb>
	callback_data = malloc(...);
	cbdataAdd(callback_data);
	...
	cbdataLock(callback_data);
	fooOperationStart(bar, callback_func, callback_data);
	...
	fooOperationComplete(...);
	if (cbdataValid(callback_data)) {
		callback_func(callback_data, ....);
	cbdataUnlock(callback_data);
	cbdataFree(callback_data);
</verb>

<P>
	With this scheme, nothing bad happens if <tt/cbdataFree/ gets called
	before <tt/cbdataUnlock/:
<verb>
	callback_data = malloc(...);
	cbdataAdd(callback_data);
	...
	cbdataLock(callback_data);
	fooOperationStart(bar, callback_func, callback_data);
	...
	cbdataFree(callback_data);
	...
	fooOperationComplete(...);
	if (cbdataValid(callback_data)) {
		callback_func(callback_data, ....);
	cbdataUnlock(callback_data);
</verb>
	In this case, when <tt/cbdataFree/ is called before 
	<tt/cbdataUnlock/, the callback_data gets marked as invalid.  Before
	executing the callback function, <tt/cbdataValid/ will return 0
	and callback_func is never executed.  When <tt/cbdataUnlock/ gets
	called, it notices that the callback_data is invalid and will
	then call <tt/cbdataFree/.

<!-- %%%% Chapter : CACHE MANAGER %%%% -->
<sect>Cache Manager

</article>
