#summary Store IO Load Handling

= Introduction =

Lusca inherited some logic for handling overloaded cache directories. This attempts to document the basic workings, the limitations/shortcomings and potential workarounds.

= Overload during storeOpen =

The store containing an object is checked via a call to the storedir "checkload()" function. If the storedir returns error or a load higher than 1000 it increments "store_io_stats.open.loadav_fail" and returns NULL.

If the store layer returns NULL then the store client code returns an error via a store client callback. I have a feeling that this somehow turns into an object "delete" from cache - either explicitly somehow due to the error condition or a subsequent object fetch replaces the on-disk version. This should be further investigated.

= Overload during storeCreate =

The two selection algorithms, "round robin" and "least load", both check to make sure the storedir is OK (load < 1000 and > 0). Storedirs which are not OK for this object are skipped by the selection logic.

= Overload during read / write IO =

The storage logic does not currently handle temporary IO overloading - the IO must complete or error, aborting the swapin/swapout. The storage modules will generally call some "sync" function to complete some pending IO before completing the current IO.

= Problems with the load handling =

The load handling was written for a forward proxy load where it was OK to occasionally miss an object. Reverse proxy loads with highly popular objects can confuse the above logic. In particular, a frequently requested object (say, a large one with range requests) seems to be evicted from the cache following a transient high load spike and this overloads the backends with range requests.